{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описание задачи\n",
    "Коллеги из другого проекта по просьбе вашей команды начали вычислять координаты событий (сообщений, подписок, реакций, регистраций), которые совершили пользователи соцсети. Значения координат будут появляться в таблице событий. Пока определяется геопозиция только исходящих сообщений, но уже сейчас можно начать разрабатывать новый функционал. \n",
    "В продукт планируют внедрить систему рекомендации друзей. Приложение будет предлагать пользователю написать человеку, если пользователь и адресат:\n",
    "\n",
    "- состоят в одном канале,\n",
    "- раньше никогда не переписывались,\n",
    "- находятся не дальше 1 км друг от друга.\n",
    "\n",
    "При этом команда хочет лучше изучить аудиторию соцсети, чтобы в будущем запустить монетизацию. Для этого было решено провести геоаналитику:\n",
    "\n",
    "- Выяснить, где находится большинство пользователей по количеству сообщений, лайков и подписок из одной точки.\n",
    "- Посмотреть, в какой точке Австралии регистрируется больше всего новых пользователей.\n",
    "- Определить, как часто пользователи путешествуют и какие города выбирают.\n",
    "\n",
    "Благодаря такой аналитике в соцсеть можно будет вставить рекламу: приложение сможет учитывать местонахождение пользователя и предлагать тому подходящие услуги компаний-партнёров. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-20\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from typing  import List\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.window import Window\n",
    "import pyspark.sql.functions as F\n",
    "import os \n",
    "import sys\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HADOOP_CONF_DIR\"] = \"/etc/hadoop/conf\"\n",
    "os.environ[\"YARN_CONF_DIR\"] = \"/etc/hadoop/conf\"\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"/usr/bin/python3\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"/usr/bin/python3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/28 11:17:18 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
      "24/05/28 11:17:21 WARN SharedInMemoryCache: Evicting cached table partition metadata from memory due to size constraints (spark.sql.hive.filesourcePartitionFileCacheSize = 262144000 bytes). This may impact query planning performance.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+-------------------+------------------+----------+\n",
      "|               event|event_type|                lat|               lon|      date|\n",
      "+--------------------+----------+-------------------+------------------+----------+\n",
      "|{NULL, NULL, 2022...|  reaction|-26.728842867329007|152.90596937369952|2022-05-30|\n",
      "|{NULL, NULL, 2022...|  reaction| -31.30616755408133|116.38841832283045|2022-05-30|\n",
      "|{NULL, NULL, 2022...|  reaction|-22.568566129738795|150.53405510107592|2022-05-30|\n",
      "|{NULL, NULL, 2022...|  reaction|-12.433534102119754|131.35071038228722|2022-05-30|\n",
      "|{NULL, NULL, 2022...|  reaction|-12.377345240540057|131.51896908518478|2022-05-30|\n",
      "|{NULL, NULL, 2022...|  reaction|-26.967101428948645|153.78804052958333|2022-05-30|\n",
      "|{NULL, NULL, 2022...|  reaction|-11.685460691926384| 130.8833764307162|2022-05-30|\n",
      "|{NULL, NULL, 2022...|  reaction| -26.74671387818525|152.08417038964188|2022-05-30|\n",
      "|{NULL, NULL, 2022...|  reaction| -26.94158521928808|152.92817870766552|2022-05-30|\n",
      "|{NULL, NULL, 2022...|  reaction|-27.096374536978264| 153.7055798510923|2022-05-30|\n",
      "+--------------------+----------+-------------------+------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Перекладываем данные по событиям из слоя сырых данных в слой ODS \n",
    "    с дополнительным партиционированием по типу события:\n",
    "    - message\n",
    "    - reaction\n",
    "    - subscription\n",
    "    - activity\n",
    "\"\"\"\n",
    "spark = SparkSession.builder \\\n",
    "                    .master(\"yarn\") \\\n",
    "                    .appName(\"EventsPartitioningJob_all_dates\") \\\n",
    "                    .config(\"spark.executor.memory\", \"2g\") \\\n",
    "                    .config(\"spark.executor.cores\", \"2\") \\\n",
    "                    .getOrCreate()\n",
    "\n",
    "\"\"\"\n",
    "    считали слой сырых данных\n",
    "\"\"\"\n",
    "events = spark.read.parquet(\"/user/master/data/geo/events\") \n",
    "\n",
    "\"\"\"\n",
    "    переложили в ODS с партиционирование по дате и типу события\n",
    "\"\"\"\n",
    "my_events = events.write.option(\"header\",True) \\\n",
    "        .partitionBy(\"date\", \"event_type\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .parquet(\"/user/yurgen001/data/geo/events\") \n",
    "\n",
    "events.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- event: struct (nullable = true)\n",
      " |    |-- admins: array (nullable = true)\n",
      " |    |    |-- element: long (containsNull = true)\n",
      " |    |-- channel_id: long (nullable = true)\n",
      " |    |-- datetime: string (nullable = true)\n",
      " |    |-- media: struct (nullable = true)\n",
      " |    |    |-- media_type: string (nullable = true)\n",
      " |    |    |-- src: string (nullable = true)\n",
      " |    |-- message: string (nullable = true)\n",
      " |    |-- message_channel_to: long (nullable = true)\n",
      " |    |-- message_from: long (nullable = true)\n",
      " |    |-- message_group: long (nullable = true)\n",
      " |    |-- message_id: long (nullable = true)\n",
      " |    |-- message_to: long (nullable = true)\n",
      " |    |-- message_ts: string (nullable = true)\n",
      " |    |-- reaction_from: string (nullable = true)\n",
      " |    |-- reaction_type: string (nullable = true)\n",
      " |    |-- subscription_channel: long (nullable = true)\n",
      " |    |-- subscription_user: string (nullable = true)\n",
      " |    |-- tags: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- user: string (nullable = true)\n",
      " |-- event_type: string (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- lon: double (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "events.printSchema()\n",
    "# геопозиция только для исходящих сообщений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 2. Создать витрину в разрезе пользователей\n",
    "\n",
    "Определите, в каком городе было совершено событие. С этим вам поможет список городов из файла geo.csv. В нём указаны координаты центра города. \n",
    "Найдите расстояние от координаты отправленного сообщения до центра города. Событие относится к тому городу, расстояние до которого наименьшее.\n",
    "В этом случае расстояние вычисляется по формуле:\n",
    "   \n",
    "d=2rarcsin⁡⁡(sin⁡2(φ2−φ12)+cos⁡⁡(φ1)cos⁡⁡(φ2)sin⁡2(λ2−λ12)).d=2rarcsin⁡(sin2(2φ2​−φ1​​)+cos⁡(φ1​)cos⁡​(φ2​)sin2(2λ2​−λ1​​)​).\n",
    "\n",
    "где:\n",
    "φ1φ1​ — широта первой точки;\n",
    "φ2φ2​ — широта второй точки;\n",
    "λ1λ1​ — долгота первой точки;\n",
    "λ2λ2​ — долгота второй точки;\n",
    "rr — радиус Земли, примерно равный 6371 км.\n",
    "\n",
    "Это формула для расчёта длины пути между двумя точками на сфере.\n",
    "Рекомендуем вам сначала самим попробовать перевести её в PySpark. Если не получится, воспользуйтесь подсказкой.\n",
    "\n",
    "Когда вы вычислите геопозицию каждого отправленного сообщения, создайте витрину с тремя полями: \n",
    "    \n",
    "- user_id — идентификатор пользователя.\n",
    "- act_city — актуальный адрес. Это город, из которого было отправлено последнее сообщение.\n",
    "- home_city — домашний адрес. Это последний город, в котором пользователь был дольше 27 дней.\n",
    "\n",
    "Выясните, сколько пользователь путешествует. Добавьте в витрину два поля:\n",
    "    \n",
    "- travel_count — количество посещённых городов. Если пользователь побывал в каком-то городе повторно, то это считается за отдельное посещение.\n",
    "- travel_array — список городов в порядке посещения.\n",
    "\n",
    "Добавьте в витрину последний атрибут — местное время (local_time) события (сообщения или других событий, если вы их разметите на основе сообщений). Местное время события — время последнего события пользователя, о котором у нас есть данные с учётом таймзоны геопозициии этого события. Данные, которые вам при этом пригодятся:\n",
    "    \n",
    "TIME_UTC — время в таблице событий. Указано в UTC+0.\n",
    "timezone — актуальный адрес. Атрибуты содержатся в виде Australia/Sydney."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1837.9808618904044\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Отладка формулы расчета расстояния между двумя точками  по их широте и долготе\n",
    "\"\"\"\n",
    "import math\n",
    " \n",
    "earth_radius = 6371 # в километрах\n",
    "lat_1 = -27.07407468786464\n",
    "lon_1 = 153.2731738967999\n",
    "lat_2 = -42.8806\n",
    "lon_2 = 147.325\n",
    "\n",
    "PI=3.14159265\n",
    "distance = 2 * earth_radius * math.asin(math.sqrt(math.pow(math.sin((math.radians(lat_1 - lat_2)) / 2), 2) + math.cos(math.radians(lat_1)) \\\n",
    "    * math.cos(math.radians(lat_2)) * math.pow(math.sin(math.radians(lon_1 - lon_2) / 2), 2))) # тоже в километрах\n",
    "\n",
    "# distance = 2 * earth_radius * math.asin(math.sqrt(math.pow(math.sin((lat_1 - lat_2) / 2), 2) + math.cos(lat_1) \\\n",
    "#     * math.cos(lat_2) * math.pow(math.sin((lon_1 - lon_2) / 2), 2))) # тоже в километрах\n",
    "print(distance)\n",
    "# messages_with_distance = messages.withColumn(\"distance\", (F.sqrt((F.sin(F.col('message_lat') - F.col('city_lat')) / F.lit(2)) + F.cos(F.col('message_lat')) * F.cos(F.col('city_lat')) * F.pow(F.sin(F.col('message_lon') - F.col('city_lon')) / F.lit(2), F.lit(2))))\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 10:38:48 WARN CacheManager: Asked to cache already cached data.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---------+------------+--------------------+--------------------+\n",
      "|user_id|  act_city|home_city|travel_count|        travel_array|          local_time|\n",
      "+-------+----------+---------+------------+--------------------+--------------------+\n",
      "|     43|Cranbourne|     NULL|           1|        [Cranbourne]|2021-05-11 14:47:...|\n",
      "|     57|    Darwin|     NULL|           1|            [Darwin]|2021-05-09 18:04:...|\n",
      "|    190|     Perth|     NULL|           1|             [Perth]|2021-04-26 10:06:...|\n",
      "|    198|    Mackay|     NULL|           3|[Mackay, Bendigo,...|2021-05-31 15:26:...|\n",
      "|    243|Townsville|     NULL|           1|        [Townsville]|2021-06-02 02:50:...|\n",
      "|    370|  Adelaide|     NULL|           1|          [Adelaide]|2021-04-30 23:04:...|\n",
      "|    442|    Mackay|     NULL|           7|[Mackay, Geelong,...| 2021-05-06 17:20:21|\n",
      "|    442|    Mackay|     NULL|           7|[Mackay, Geelong,...| 2021-05-06 17:20:21|\n",
      "|    487|    Cairns|     NULL|           1|            [Cairns]|2021-05-08 03:16:...|\n",
      "|    588| Toowoomba|     NULL|           1|         [Toowoomba]|2021-06-01 02:50:...|\n",
      "|    589|Launceston|     NULL|           1|        [Launceston]|2021-06-10 10:01:...|\n",
      "|    624| Melbourne|     NULL|          78|[Perth, Melbourne...| 2021-05-17 19:48:07|\n",
      "|    624| Melbourne|     NULL|          78|[Perth, Melbourne...| 2021-05-17 19:48:07|\n",
      "|    624| Melbourne|     NULL|          78|[Perth, Melbourne...| 2021-05-17 19:48:07|\n",
      "|    624| Melbourne|     NULL|          78|[Perth, Melbourne...| 2021-05-17 19:48:07|\n",
      "|    624| Melbourne|     NULL|          78|[Perth, Melbourne...| 2021-05-17 19:48:07|\n",
      "|    693|   Bendigo|     NULL|           1|           [Bendigo]|2021-04-24 08:04:...|\n",
      "|    696|Townsville|     NULL|           1|        [Townsville]|2021-04-23 20:59:...|\n",
      "|    700|    Sydney|     NULL|           1|            [Sydney]|2021-04-25 03:55:...|\n",
      "|    814|Launceston|     NULL|           1|        [Launceston]|2021-04-25 06:03:...|\n",
      "|    828|    Mackay|     NULL|           2|    [Darwin, Mackay]|2021-05-19 17:04:...|\n",
      "|    858| Melbourne|     NULL|           1|         [Melbourne]| 2021-04-27 23:10:37|\n",
      "|    902|  Brisbane|     NULL|           1|          [Brisbane]|2021-05-05 08:59:...|\n",
      "|    909| Melbourne|     NULL|           3|[Cairns, Sydney, ...|2021-05-13 05:29:...|\n",
      "|    936|Launceston|     NULL|           1|        [Launceston]|2021-05-20 14:19:...|\n",
      "|   1185|   Bunbury|     NULL|           1|           [Bunbury]|2021-04-28 11:19:...|\n",
      "|   1200|    Cairns|     NULL|           1|            [Cairns]|2021-04-28 20:00:...|\n",
      "|   1202|  Maitland|     NULL|           1|          [Maitland]|2021-05-08 00:39:...|\n",
      "|   1329|Launceston|     NULL|           2|[Maitland, Launce...|2021-05-04 08:48:...|\n",
      "|   1361| Melbourne|     NULL|           4|[Brisbane, Darwin...|2021-05-09 11:22:...|\n",
      "|   1513|  Brisbane|     NULL|           1|          [Brisbane]|2021-05-02 21:19:...|\n",
      "|   1632| Melbourne|     NULL|           1|         [Melbourne]|2021-04-27 01:48:...|\n",
      "|   1728|Townsville|     NULL|           1|        [Townsville]|2021-04-27 08:26:...|\n",
      "|   1806|    Mackay|     NULL|           5|[Mackay, Bendigo,...|2021-06-04 08:58:...|\n",
      "|   1831|  Maitland|     NULL|           1|          [Maitland]|2021-04-25 19:07:...|\n",
      "|   1893|    Mackay|     NULL|           1|            [Mackay]|2021-05-01 10:37:...|\n",
      "|   1918|    Hobart|     NULL|           1|            [Hobart]|2021-05-27 04:42:...|\n",
      "|   1937|    Hobart|     NULL|           1|            [Hobart]|2021-05-02 07:48:...|\n",
      "|   1942|Wollongong|     NULL|           2|[Brisbane, Wollon...|2021-05-27 00:19:...|\n",
      "|   1945|  Maitland|     NULL|           1|          [Maitland]|2021-04-26 15:07:...|\n",
      "+-------+----------+---------+------------+--------------------+--------------------+\n",
      "only showing top 40 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from typing  import List\n",
    "import pyspark\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.window import Window\n",
    "import pyspark.sql.functions as F\n",
    "import os \n",
    "import sys\n",
    "\n",
    "os.environ[\"HADOOP_CONF_DIR\"] = \"/etc/hadoop/conf\"\n",
    "os.environ[\"YARN_CONF_DIR\"] = \"/etc/hadoop/conf\"\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"/usr/bin/python3\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"/usr/bin/python3\"\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "                    .master(\"yarn\") \\\n",
    "                    .appName(\"datamartByUsersJob\") \\\n",
    "                    .config(\"spark.executor.memory\", \"2g\") \\\n",
    "                    .config(\"spark.executor.cores\", \"2\") \\\n",
    "                    .getOrCreate()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "    формирование списка партиций по дате на заданную глубину\n",
    "\"\"\"\n",
    "def input_paths(date: str, depth: int, base_path: str) -> List:\n",
    "    dt = datetime.strptime(date, '%Y-%m-%d').date()\n",
    "    path_list = [base_path + '/date=' + (dt - timedelta(days=i)).strftime('%Y-%m-%d')\n",
    "                 for i in range(depth)\n",
    "                ]\n",
    "    return path_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def datamart_by_users(base_path:str, date: str, depth: int, spark: SparkSession) -> DataFrame:\n",
    "\n",
    "    DAYS_COUNT = 27 # время непрерывного нахождения для определения домашнего города\n",
    "    EARTH_RADIUS = 6371\n",
    "\n",
    "    \"\"\"\n",
    "        Формируем и вычитываем список партиций на заданную глубину с заданной даты\n",
    "    \"\"\"\n",
    "    events_path = input_paths(date, depth, base_path)\n",
    "#     print(events_path)\n",
    "    events = spark.read.option('basePath', base_path).parquet(*events_path)\n",
    "#     events.printSchema()\n",
    "\n",
    "    \"\"\"\n",
    "        считываем файл geo.csv с координатами городов\n",
    "        преобразуем долготу и широту из строкового типа в числовой\n",
    "    \"\"\"\n",
    "    schema_geo_csv = StructType([ \n",
    "        StructField(\"id\",IntegerType(),True), \n",
    "        StructField(\"city\",StringType(),True), \n",
    "        StructField(\"lat\",StringType(),True), \n",
    "        StructField(\"lng\",StringType(),True)\n",
    "    ])    \n",
    "    \n",
    "    geo_city = spark.read.options(delimiter=\";\", header=True) \\\n",
    "                         .schema(schema_geo_csv) \\\n",
    "                         .csv(\"/user/yurgen001/data/snapshots/geo_city\") \\\n",
    "                         .withColumn(\"lat\", F.regexp_replace(\"lat\", \",\", \".\").cast(DoubleType())) \\\n",
    "                         .withColumn(\"lng\", F.regexp_replace(\"lng\", \",\", \".\").cast(DoubleType()))\n",
    "#     geo_city.printSchema()\n",
    "#     geo_city.show(10)\n",
    "\n",
    "       \n",
    "    \"\"\"\n",
    "        выделяем id пользователя, как id отправителя сообщения (координаты внедрены только для событий типа исходящих сообщений)\n",
    "        джойним полученное со списком городов как декартово произведение все со всеми,\n",
    "        чтобы в дальнейшем посчитать дистанцию до всех городов и выбрать минимальную\n",
    "    \"\"\"\n",
    "    messages = events.where(\"event_type = 'message' AND event.message_ts IS NOT NULL\") \\\n",
    "                     .selectExpr(\"event.message_from AS user_id\",\n",
    "                                 \"event.message_ts AS message_dt\",\n",
    "                                 \"lat AS message_lat\",\n",
    "                                 \"lon AS message_lon\") \\\n",
    "                     .crossJoin(geo_city.withColumnRenamed(\"lat\", \"city_lat\").withColumnRenamed(\"lng\", \"city_lon\")) \n",
    "\n",
    "#     messages.show()\n",
    "  \n",
    "\n",
    "    \"\"\"\n",
    "        добавляем поле дистанции до города, таким образом у нас есть заготовка с дистанциями до всех городов списка    \n",
    "    \"\"\"\n",
    "    messages_with_distance = messages.withColumn(\"distance\", 2 * EARTH_RADIUS * F.asin(F.sqrt(F.pow(F.sin((F.radians('message_lat') - F.radians('city_lat')) / F.lit(2)), F.lit(2)) \\\n",
    "                    + F.cos(F.radians('message_lat')) * F.cos(F.radians('city_lat')) * F.pow(F.sin((F.radians('message_lon') - F.radians('city_lon')) / F.lit(2)), F.lit(2))))\n",
    "                                                )\n",
    "    \n",
    "#     messages_with_distance.show()\n",
    "    # distance_rank_window = Window().partitionBy(\"user_id\", \"message_dt\").orderBy(\"distance\")\n",
    "    # messages_with_city = messages_with_distance.select(\"user_id\", \"message_dt\", \"city\", \"distance\") \\\n",
    "    #                                            .withColumn(\"distance_rank\", F.row_number().over(distance_rank_window)) \\\n",
    "    #                                            .where(\"distance_rank = 1\") \\\n",
    "    #                                            .selectExpr(\"user_id\",\n",
    "    #                                                        \"message_dt\",\n",
    "    #                                                        \"city\")\n",
    "\n",
    "    \"\"\"\n",
    "        Найдем город отправки сообщения (это город, дистанция до которого минимальна)\n",
    "     \n",
    "    \"\"\"\n",
    "    distance_rank_window = Window().partitionBy(\"user_id\", \"message_dt\").orderBy(\"distance\")\n",
    "    messages_with_city = messages_with_distance.select(\"user_id\",\n",
    "                                                       \"message_dt\",\n",
    "                                                       \"message_lat\",\n",
    "                                                       \"message_lon\",\n",
    "                                                       \"city\",\n",
    "                                                       \"distance\") \\\n",
    "                                               .withColumn(\"distance_rank\", F.row_number().over(distance_rank_window)) \\\n",
    "                                               .where(\"distance_rank = 1\") \\\n",
    "                                               .select(\"user_id\",\n",
    "                                                       \"message_dt\",\n",
    "                                                       \"message_lat\",\n",
    "                                                       \"message_lon\",\n",
    "                                                       \"city\")\n",
    "\n",
    "\n",
    "    messages_with_city.cache()\n",
    "#     messages_with_city.show()\n",
    "\n",
    "    \"\"\"\n",
    "        Находим актуальный адрес\n",
    "        город, из которого было отправлено последнее сообщение\n",
    "    \"\"\"\n",
    "    last_dt_window = Window().partitionBy(\"user_id\").orderBy(F.desc(\"message_dt\"))\n",
    "    # user_act_city = messages_with_city.withColumn(\"dt_rank\", F.row_number().over(last_dt_window)) \\\n",
    "    #                                   .where(\"dt_rank = 1\") \\\n",
    "    #                                   .selectExpr(\"user_id\", \"city AS act_city\", \\\n",
    "    #                                               \"CONCAT('Australia/', city) AS time_zone\", \\\n",
    "    #                                               \"FROM_UTC_TIMESTAMP(message_dt, CONCAT('Australia/', 'Sydney')) AS local_time\"                            \n",
    "    #                                              ) \n",
    "\n",
    "    user_act_location = messages_with_city.withColumn(\"dt_rank\", F.row_number().over(last_dt_window)) \\\n",
    "                                          .where(\"dt_rank = 1\") \\\n",
    "                                          .selectExpr(\"user_id\",\n",
    "                                                      \"message_lat AS act_lat\",\n",
    "                                                      \"message_lon AS act_lon\",\n",
    "                                                      \"city AS act_city\", \n",
    "                                                      \"CONCAT('Australia/', city) AS time_zone\",\n",
    "                                                      \"FROM_UTC_TIMESTAMP(message_dt, CONCAT('Australia/', 'Sydney')) AS local_time\"                            \n",
    "                                                      ) \n",
    "\n",
    "\n",
    "#     user_act_location.show(10, False)\n",
    "    \"\"\"\n",
    "        делаем заготовку для поиска домашнего города и списка посещенных городов\n",
    "        для этого нам надо знать сколько дней пользователь провел в каждом городе последовательно\n",
    "        делаем два столбца row_number один сгруппирован только по пользователю а второй по пользователю и по городу\n",
    "        пока пользователь в городе разность между столбцами постоянна, при смене города она меняется и служит номером визита в город \n",
    "        нумерация начинается с нуля (нашел решение на стековерфлоу)\n",
    "    \"\"\"\n",
    "    seq_num_window = Window().partitionBy(\"user_id\").orderBy(\"message_dt\")\n",
    "    seq_num_city_window = Window().partitionBy(\"user_id\", \"city\").orderBy(\"message_dt\")\n",
    "    user_city_visits = messages_with_city.withColumn(\"seq_num\", F.row_number().over(seq_num_window)) \\\n",
    "                                         .withColumn(\"seq_num_city\", F.row_number().over(seq_num_city_window)) \\\n",
    "                                         .withColumn(\"visit_num\", F.col(\"seq_num\") - F.col(\"seq_num_city\"))\n",
    "\n",
    "#     user_city_visits.show(40, False)\n",
    "    \"\"\"\n",
    "        считаем длительность каждого визита пользователя в город в днях, метки начала и конца визита по \n",
    "        минимальной и максимальной метке отправки сообщения \n",
    "    \"\"\"\n",
    "    user_city_visits = user_city_visits.groupBy(\"user_id\", \"city\", \"visit_num\") \\\n",
    "                                       .agg(F.min(\"message_dt\").alias(\"start_visit_dt\"), \\\n",
    "                                            F.max(\"message_dt\").alias(\"end_visit_dt\"), \\\n",
    "                                           ) \\\n",
    "                                       .withColumn(\"visit_day_count\", F.datediff(F.to_date(\"end_visit_dt\"), F.to_date(\"start_visit_dt\")))\n",
    "#     user_city_visits.show(40, False)\n",
    "\n",
    "    \"\"\"\n",
    "        в проекте эти вычисления нужны для всех трех витрин и будут выделены в отдельный модуль\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "        Находим последний город, в котором пользователь провел не менее 27 дней (домашний адрес)\n",
    "    \"\"\"\n",
    "    home_city_window = Window().partitionBy(\"user_id\").orderBy(F.desc(\"start_visit_dt\"))\n",
    "    user_home_city = user_city_visits.where(f\"visit_day_count >= {DAYS_COUNT}\") \\\n",
    "                                     .withColumn(\"home_city_rank\", F.row_number().over(home_city_window)) \\\n",
    "                                     .where(\"home_city_rank = 1\") \\\n",
    "                                     .selectExpr(\"user_id\",\n",
    "                                                 \"city AS home_city\")             \n",
    "#     user_home_city.show()\n",
    "    \"\"\"\n",
    "        Считаем для каждого пользователя число посещенных городов и формируем список городов в порядке посещения\n",
    "    \"\"\"\n",
    "    user_travel = user_city_visits.orderBy(\"start_visit_dt\") \\\n",
    "                                  .groupBy(\"user_id\") \\\n",
    "                                  .agg(F.count(\"city\").alias(\"travel_count\"), \\\n",
    "                                       F.collect_list(\"city\").alias(\"travel_array\")\n",
    "                                      )                     \n",
    "#     user_travel.show(40, False)\n",
    "    \"\"\"\n",
    "        Собираем витрину по пользователю\n",
    "    \"\"\"\n",
    "    user_datamart = user_act_location.join(user_travel, \"user_id\", \"left\") \\\n",
    "                                 .join(user_home_city, \"user_id\", \"left\") \\\n",
    "                                 .select(\"user_id\",\n",
    "                                         \"act_city\",\n",
    "                                         \"home_city\",\n",
    "                                         \"travel_count\",\n",
    "                                         \"travel_array\",\n",
    "                                         \"local_time\")\n",
    "    user_datamart.show()\n",
    "\n",
    "    return user_datamart\n",
    "    \n",
    "    # user_travel_array = user_city_visits.orderBy(\"start_visit_dt\") \\\n",
    "    #                                     .groupBy(\"user_id\") \\\n",
    "    #                                     .agg(F.collect_list(\"city\").alias(\"travel_array\"))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    datamart_by_users(\"/user/yurgen001/data/geo/events\", '2022-05-31', 60, spark)#.repartition(1) \\\n",
    "        #.write.mode('overwrite').parquet('/user/yurgen001/data/analytics/dm_by_user_d60')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 3. Создать витрину в разрезе зон\n",
    "Вы создадите геослой — найдёте распределение атрибутов, связанных с событиями, по географическим зонам (городам). Если проанализировать этот слой, то можно понять поведение пользователей по различным регионам. \n",
    "Итак, вам нужно посчитать количество событий в конкретном городе за неделю и месяц. Значит, витрина будет содержать следующие поля:\n",
    "\n",
    "- month — месяц расчёта;\n",
    "- week — неделя расчёта;\n",
    "- zone_id — идентификатор зоны (города);\n",
    "- week_message — количество сообщений за неделю;\n",
    "- week_reaction — количество реакций за неделю;\n",
    "- week_subscription — количество подписок за неделю;\n",
    "- week_user — количество регистраций за неделю;\n",
    "- month_message — количество сообщений за месяц;\n",
    "- month_reaction — количество реакций за месяц;\n",
    "- month_subscription — количество подписок за месяц;\n",
    "- month_user — количество регистраций за месяц.\n",
    "\n",
    "В этой витрине вы учитываете не только отправленные сообщения, но и другие действия — подписки, реакции, регистрации (рассчитываются по первым сообщениям). Пока присвойте таким событиям координаты последнего отправленного сообщения конкретного пользователя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/28 11:45:22 WARN CacheManager: Asked to cache already cached data.        \n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+--------+------------+-------------+-----------------+---------+-------------+--------------+------------------+----------+\n",
      "|              month|               week| zone_id|week_message|week_reaction|week_subscription|week_user|month_message|month_reaction|month_subscription|month_user|\n",
      "+-------------------+-------------------+--------+------------+-------------+-----------------+---------+-------------+--------------+------------------+----------+\n",
      "|2021-04-01 00:00:00|2021-03-29 00:00:00|Adelaide|         550|            0|                0|      298|         3445|             0|                 0|       949|\n",
      "|2021-04-01 00:00:00|2021-04-05 00:00:00|Adelaide|        1065|            0|                0|      272|         3445|             0|                 0|       949|\n",
      "|2021-04-01 00:00:00|2021-04-12 00:00:00|Adelaide|         852|            0|                0|      180|         3445|             0|                 0|       949|\n",
      "|2021-04-01 00:00:00|2021-04-19 00:00:00|Adelaide|         648|            0|                0|      128|         3445|             0|                 0|       949|\n",
      "|2021-04-01 00:00:00|2021-04-26 00:00:00|Adelaide|         330|            0|                0|       71|         3445|             0|                 0|       949|\n",
      "|2021-05-01 00:00:00|2021-04-26 00:00:00|Adelaide|         137|            0|                0|       35|         1220|             0|                 0|       212|\n",
      "|2021-05-01 00:00:00|2021-05-03 00:00:00|Adelaide|         390|            0|                0|       79|         1220|             0|                 0|       212|\n",
      "|2021-05-01 00:00:00|2021-05-10 00:00:00|Adelaide|         317|            0|                0|       52|         1220|             0|                 0|       212|\n",
      "|2021-05-01 00:00:00|2021-05-17 00:00:00|Adelaide|         254|            0|                0|       35|         1220|             0|                 0|       212|\n",
      "|2021-05-01 00:00:00|2021-05-24 00:00:00|Adelaide|         113|            0|                0|       10|         1220|             0|                 0|       212|\n",
      "|2021-05-01 00:00:00|2021-05-31 00:00:00|Adelaide|           9|            0|                0|        1|         1220|             0|                 0|       212|\n",
      "|2022-04-01 00:00:00|2022-03-28 00:00:00|Adelaide|           0|         1275|             2662|        0|            0|         25576|             49521|         0|\n",
      "|2022-04-01 00:00:00|2022-04-04 00:00:00|Adelaide|           0|         5089|             9911|        0|            0|         25576|             49521|         0|\n",
      "|2022-04-01 00:00:00|2022-04-11 00:00:00|Adelaide|           0|         5771|            11268|        0|            0|         25576|             49521|         0|\n",
      "|2022-04-01 00:00:00|2022-04-18 00:00:00|Adelaide|           0|         6779|            13009|        0|            0|         25576|             49521|         0|\n",
      "|2022-04-01 00:00:00|2022-04-25 00:00:00|Adelaide|           0|         6662|            12671|        0|            0|         25576|             49521|         0|\n",
      "|2022-05-01 00:00:00|2022-04-25 00:00:00|Adelaide|           0|         1231|             2257|        0|            0|         57240|            113974|         0|\n",
      "|2022-05-01 00:00:00|2022-05-02 00:00:00|Adelaide|           0|         9107|            17727|        0|            0|         57240|            113974|         0|\n",
      "|2022-05-01 00:00:00|2022-05-09 00:00:00|Adelaide|           0|        10707|            21119|        0|            0|         57240|            113974|         0|\n",
      "|2022-05-01 00:00:00|2022-05-16 00:00:00|Adelaide|           0|        13164|            25880|        0|            0|         57240|            113974|         0|\n",
      "|2022-05-01 00:00:00|2022-05-23 00:00:00|Adelaide|           0|        18822|            36764|        0|            0|         57240|            113974|         0|\n",
      "|2022-05-01 00:00:00|2022-05-30 00:00:00|Adelaide|           0|         4209|            10227|        0|            0|         57240|            113974|         0|\n",
      "|2021-04-01 00:00:00|2021-03-29 00:00:00|Ballarat|         161|            0|                0|       64|         1193|             0|                 0|       306|\n",
      "|2021-04-01 00:00:00|2021-04-05 00:00:00|Ballarat|         333|            0|                0|      101|         1193|             0|                 0|       306|\n",
      "|2021-04-01 00:00:00|2021-04-12 00:00:00|Ballarat|         337|            0|                0|       70|         1193|             0|                 0|       306|\n",
      "|2021-04-01 00:00:00|2021-04-19 00:00:00|Ballarat|         232|            0|                0|       44|         1193|             0|                 0|       306|\n",
      "|2021-04-01 00:00:00|2021-04-26 00:00:00|Ballarat|         130|            0|                0|       27|         1193|             0|                 0|       306|\n",
      "|2021-05-01 00:00:00|2021-04-26 00:00:00|Ballarat|          51|            0|                0|       10|          329|             0|                 0|        56|\n",
      "|2021-05-01 00:00:00|2021-05-03 00:00:00|Ballarat|         108|            0|                0|       22|          329|             0|                 0|        56|\n",
      "|2021-05-01 00:00:00|2021-05-10 00:00:00|Ballarat|         102|            0|                0|       18|          329|             0|                 0|        56|\n",
      "|2021-05-01 00:00:00|2021-05-17 00:00:00|Ballarat|          50|            0|                0|        4|          329|             0|                 0|        56|\n",
      "|2021-05-01 00:00:00|2021-05-24 00:00:00|Ballarat|          18|            0|                0|        2|          329|             0|                 0|        56|\n",
      "|2022-04-01 00:00:00|2022-03-28 00:00:00|Ballarat|           0|          429|              797|        0|            0|          8143|             15724|         0|\n",
      "|2022-04-01 00:00:00|2022-04-04 00:00:00|Ballarat|           0|         1590|             3145|        0|            0|          8143|             15724|         0|\n",
      "|2022-04-01 00:00:00|2022-04-11 00:00:00|Ballarat|           0|         1899|             3564|        0|            0|          8143|             15724|         0|\n",
      "|2022-04-01 00:00:00|2022-04-18 00:00:00|Ballarat|           0|         2183|             4175|        0|            0|          8143|             15724|         0|\n",
      "|2022-04-01 00:00:00|2022-04-25 00:00:00|Ballarat|           0|         2042|             4043|        0|            0|          8143|             15724|         0|\n",
      "|2022-05-01 00:00:00|2022-04-25 00:00:00|Ballarat|           0|          362|              766|        0|            0|         18230|             36244|         0|\n",
      "|2022-05-01 00:00:00|2022-05-02 00:00:00|Ballarat|           0|         2835|             5572|        0|            0|         18230|             36244|         0|\n",
      "|2022-05-01 00:00:00|2022-05-09 00:00:00|Ballarat|           0|         3433|             6685|        0|            0|         18230|             36244|         0|\n",
      "+-------------------+-------------------+--------+------------+-------------+-----------------+---------+-------------+--------------+------------------+----------+\n",
      "only showing top 40 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from typing  import List\n",
    "import pyspark\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.window import Window\n",
    "import pyspark.sql.functions as F\n",
    "import os \n",
    "import sys\n",
    "\n",
    "os.environ[\"HADOOP_CONF_DIR\"] = \"/etc/hadoop/conf\"\n",
    "os.environ[\"YARN_CONF_DIR\"] = \"/etc/hadoop/conf\"\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"/usr/bin/python3\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"/usr/bin/python3\"\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "                    .master(\"yarn\") \\\n",
    "                    .appName(\"datamartByZoneJob\") \\\n",
    "                    .config(\"spark.executor.memory\", \"2g\") \\\n",
    "                    .config(\"spark.executor.cores\", \"2\") \\\n",
    "                    .getOrCreate()\n",
    "\n",
    "\n",
    "def input_paths(date: str, depth: int, base_path: str) -> List:\n",
    "    dt = datetime.strptime(date, '%Y-%m-%d').date()\n",
    "    path_list = [base_path + '/date=' + (dt - timedelta(days=i)).strftime('%Y-%m-%d')\n",
    "                 for i in range(depth)\n",
    "                ]\n",
    "    return path_list\n",
    "\n",
    "\n",
    "def datamart_by_zone(base_path:str, date: str, depth: int, spark: SparkSession) -> DataFrame:\n",
    "\n",
    "    EARTH_RADIUS = 6371\n",
    "\n",
    "    events_path = input_paths(date, depth, base_path)\n",
    "#     print(events_path)\n",
    "    events = spark.read.option('basePath', base_path).parquet(*events_path)\n",
    "#     events.printSchema()\n",
    "    schema_geo_csv = StructType([ \n",
    "        StructField(\"id\",IntegerType(),True), \n",
    "        StructField(\"city\",StringType(),True), \n",
    "        StructField(\"lat\",StringType(),True), \n",
    "        StructField(\"lng\",StringType(),True)\n",
    "    ])    \n",
    "    \n",
    "    geo_city = spark.read.options(delimiter=\";\", header=True) \\\n",
    "                         .schema(schema_geo_csv) \\\n",
    "                         .csv(\"/user/yurgen001/data/snapshots/geo_city\") \\\n",
    "                         .withColumn(\"lat\", F.regexp_replace(\"lat\", \",\", \".\").cast(DoubleType())) \\\n",
    "                         .withColumn(\"lng\", F.regexp_replace(\"lng\", \",\", \".\").cast(DoubleType()))\n",
    "#     geo_city.printSchema()\n",
    "#     geo_city.show(10)\n",
    "\n",
    "  \n",
    "    messages = events.where(\"event_type = 'message' AND event.message_ts IS NOT NULL\") \\\n",
    "                     .selectExpr(\"event.message_from AS user_id\", \"event.message_ts AS message_dt\", \"lat AS message_lat\", \"lon AS message_lon\") \\\n",
    "                     .crossJoin(geo_city.withColumnRenamed(\"lat\", \"city_lat\") \\\n",
    "                                        .withColumnRenamed(\"lng\", \"city_lon\")) \n",
    "\n",
    "#     messages.show()\n",
    "  \n",
    "    messages_with_distance = messages.withColumn(\"distance\", 2 * EARTH_RADIUS * F.asin(F.sqrt(F.pow(F.sin((F.radians('message_lat') - F.radians('city_lat')) / F.lit(2)), F.lit(2)) \\\n",
    "                    + F.cos(F.radians('message_lat')) * F.cos(F.radians('city_lat')) * F.pow(F.sin((F.radians('message_lon') - F.radians('city_lon')) / F.lit(2)), F.lit(2))))\n",
    "                                                )\n",
    "    \n",
    "#     messages_with_distance.show()\n",
    "    # distance_rank_window = Window().partitionBy(\"user_id\", \"message_dt\").orderBy(\"distance\")\n",
    "    # messages_with_city = messages_with_distance.select(\"user_id\", \"message_dt\", \"city\", \"distance\") \\\n",
    "    #                                            .withColumn(\"distance_rank\", F.row_number().over(distance_rank_window)) \\\n",
    "    #                                            .where(\"distance_rank = 1\") \\\n",
    "    #                                            .selectExpr(\"user_id\",\n",
    "    #                                                        \"message_dt\",\n",
    "    #                                                        \"city\")\n",
    "\n",
    "    distance_rank_window = Window().partitionBy(\"user_id\", \"message_dt\").orderBy(\"distance\")\n",
    "    messages_with_city = messages_with_distance.select(\"user_id\",\n",
    "                                                       \"message_dt\",\n",
    "                                                       \"message_lat\",\n",
    "                                                       \"message_lon\",\n",
    "                                                       \"city\",\n",
    "                                                       \"distance\") \\\n",
    "                                               .withColumn(\"distance_rank\", F.row_number().over(distance_rank_window)) \\\n",
    "                                               .where(\"distance_rank = 1\") \\\n",
    "                                               .select(\"user_id\",\n",
    "                                                       \"message_dt\",\n",
    "                                                       \"message_lat\",\n",
    "                                                       \"message_lon\",\n",
    "                                                       \"city\")\n",
    "\n",
    "\n",
    "    messages_with_city.cache()\n",
    "#     messages_with_city.show()\n",
    "\n",
    "\n",
    "    \n",
    "    last_dt_window = Window().partitionBy(\"user_id\").orderBy(F.desc(\"message_dt\"))\n",
    "    # user_act_city = messages_with_city.withColumn(\"dt_rank\", F.row_number().over(last_dt_window)) \\\n",
    "    #                                   .where(\"dt_rank = 1\") \\\n",
    "    #                                   .selectExpr(\"user_id\", \"city AS act_city\")\n",
    "\n",
    "\n",
    "    user_act_location = messages_with_city.withColumn(\"dt_rank\", F.row_number().over(last_dt_window)) \\\n",
    "                                          .where(\"dt_rank = 1\") \\\n",
    "                                          .selectExpr(\"user_id\",\n",
    "                                                      \"message_lat AS act_lat\",\n",
    "                                                      \"message_lon AS act_lon\",\n",
    "                                                      \"city AS act_city\", \n",
    "                                                      \"CONCAT('Australia/', city) AS time_zone\",\n",
    "                                                      \"FROM_UTC_TIMESTAMP(message_dt, CONCAT('Australia/', 'Sydney')) AS local_time\"                            \n",
    "                                                      ) \n",
    "\n",
    "#     user_act_city.show()\n",
    "\n",
    "    \"\"\"\n",
    "        _______________________________________________________________________________________\n",
    "        до этого места вычиления те же, что и в первой витрине\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "        Формируем данные по сообщениям  из уже предобработанного датасета \n",
    "    \"\"\"\n",
    "    out_messages = messages_with_city.selectExpr(\"TO_DATE(message_dt) AS event_date\",\n",
    "                                                 \"'message' AS event_type\",\n",
    "                                                 \"city AS zone_id\")\n",
    "    \n",
    "#     out_messages.show()\n",
    "\n",
    "    \"\"\"\n",
    "        Формируем данные по реакциям из основной таблицы событий\n",
    "        зону берем из текущего положения пользователя\n",
    "    \"\"\"\n",
    "    out_reactions = events.where(\"event_type = 'reaction'\") \\\n",
    "                      .selectExpr(\"CAST(event.reaction_from AS LONG) AS user_id\",\n",
    "                                  \"TO_DATE(event.datetime) AS event_date\") \\\n",
    "                      .join(user_act_location, \"user_id\", \"inner\") \\\n",
    "                      .selectExpr(\"event_date\",\n",
    "                                  \"'reaction' AS event_type\",\n",
    "                                  \"act_city AS zone_id\")\n",
    "    \n",
    "#     out_reactions.printSchema()\n",
    "#     out_reactions.show()\n",
    "    \n",
    "    \"\"\"\n",
    "        Формируем данные по подпискам из основной таблицы событий\n",
    "        зону берем из текущего положения пользователя\n",
    "    \"\"\"\n",
    "\n",
    "    out_subscriptions = events.where(\"event_type = 'subscription'\") \\\n",
    "                              .selectExpr(\"CAST(event.user AS LONG) AS user_id\",\n",
    "                                          \"TO_DATE(event.datetime) AS event_date\") \\\n",
    "                              .join(user_act_location, \"user_id\", \"inner\") \\\n",
    "                              .selectExpr(\"event_date\",\n",
    "                                          \"'subscription' AS event_type\",\n",
    "                                          \"act_city AS zone_id\")\n",
    "    \n",
    "#     out_subscriptions.printSchema()\n",
    "#     out_subscriptions.show()\n",
    "    \"\"\"\n",
    "        Собираем таблицу первых сообщений пользователя (в каком городе оно отпаравлено) \n",
    "        эти координаты мы присвоим событию регистрации поскольку геопозиционирование \n",
    "        у нас пока реализовано только для отправленных сообщений\n",
    "    \"\"\"\n",
    "    first_dt_window = Window().partitionBy(\"user_id\").orderBy(\"message_dt\")\n",
    "    user_first_message = messages_with_city.withColumn(\"dt_rank\", F.row_number().over(first_dt_window)) \\\n",
    "                                          .where(\"dt_rank = 1\") \\\n",
    "                                          .selectExpr(\"user_id\",\n",
    "                                                      \"message_dt\",\n",
    "                                                      \"city\"\n",
    "                                                      ) \n",
    "    \"\"\"\n",
    "        Формируем данные по регистрациям из таблицы первых сообщений пользователя\n",
    "    \"\"\"\n",
    "\n",
    "    out_registrations = user_first_message.selectExpr(\"TO_DATE(message_dt) AS event_date\",\n",
    "                                                      \"'registration' AS event_type\",\n",
    "                                                      \"city AS zone_id\")\n",
    "\n",
    "#     out_registrations.printSchema()\n",
    "#     out_registrations.show()\n",
    "    \"\"\"\n",
    "        Объединяем все типы событий в единую таблицу и добавляем неделю и месяц события\n",
    "    \"\"\"\n",
    "    all_events =  out_messages.unionByName(out_reactions) \\\n",
    "                              .unionByName(out_subscriptions) \\\n",
    "                              .unionByName(out_registrations) \\\n",
    "                              .withColumn(\"week\", F.date_trunc(\"week\", \"event_date\")) \\\n",
    "                              .withColumn(\"month\", F.date_trunc(\"month\", \"event_date\"))\n",
    "#     all_events.show()\n",
    "\n",
    "    \"\"\"\n",
    "        Собираем витрину по неделям\n",
    "    \"\"\"\n",
    "    zone_datamart_by_week = all_events.groupBy(\"zone_id\", \"month\", \"week\") \\\n",
    "                                      .pivot(\"event_type\", [\"message\", \"reaction\", \"subscription\", \"registration\"]) \\\n",
    "                                      .agg(F.count(\"event_date\")) \\\n",
    "                                      .withColumnRenamed(\"message\", \"week_message\") \\\n",
    "                                      .withColumnRenamed(\"reaction\", \"week_reaction\") \\\n",
    "                                      .withColumnRenamed(\"subscription\", \"week_subscription\") \\\n",
    "                                      .withColumnRenamed(\"registration\", \"week_user\")\n",
    "                                      \n",
    "    \n",
    "#     zone_datamart_by_week.show(100)\n",
    "    \"\"\"\n",
    "        Собираем витрину по месяцам (минус одна группировка по неделям)\n",
    "    \"\"\"\n",
    "    zone_datamart_by_month = all_events.groupBy(\"zone_id\", \"month\") \\\n",
    "                                       .pivot(\"event_type\", [\"message\", \"reaction\", \"subscription\", \"registration\"]) \\\n",
    "                                       .agg(F.count(\"event_date\")) \\\n",
    "                                       .withColumnRenamed(\"message\", \"month_message\") \\\n",
    "                                       .withColumnRenamed(\"reaction\", \"month_reaction\") \\\n",
    "                                       .withColumnRenamed(\"subscription\", \"month_subscription\") \\\n",
    "                                       .withColumnRenamed(\"registration\", \"month_user\")\n",
    "                                      \n",
    "    \n",
    "#     zone_datamart_by_month.show(100)\n",
    "    \"\"\"\n",
    "        Объединяем данные в выходную витрину\n",
    "    \"\"\"\n",
    "    zone_datamart = zone_datamart_by_week.join(zone_datamart_by_month, [\"zone_id\", \"month\"], \"inner\") \\\n",
    "                                         .select(\"month\",\n",
    "                                                 \"week\",\n",
    "                                                 \"zone_id\",\n",
    "                                                 \"week_message\",\n",
    "                                                 \"week_reaction\",\n",
    "                                                 \"week_subscription\",\n",
    "                                                 \"week_user\",\n",
    "                                                 \"month_message\",\n",
    "                                                 \"month_reaction\",\n",
    "                                                 \"month_subscription\",\n",
    "                                                 \"month_user\",\n",
    "                                                ) \\\n",
    "                                         .orderBy(\"zone_id\", \"month\", \"week\") \\\n",
    "                                         .na.fill(value=0)\n",
    "#     zone_datamart.show(40)\n",
    "    return zone_datamart\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    datamart_by_zone(\"/user/yurgen001/data/geo/events\", '2022-05-31', 60, spark)#.repartition(1) \\\n",
    "        #.write.mode('overwrite').parquet('/user/yurgen001/data/analytics/dm_by_zone_d60')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 4. Построить витрину для рекомендации друзей\n",
    "Напомним, как будет работать рекомендация друзей: если пользователи подписаны на один канал, ранее никогда не переписывались и расстояние между ними не превышает 1 км, то им обоим будет предложено добавить другого в друзья. Образовывается парный атрибут, который обязан быть уникальным: порядок упоминания не должен создавать дубли пар.\n",
    "Витрина будет содержать следующие атрибуты:\n",
    "\n",
    "- user_left — первый пользователь;\n",
    "- user_right — второй пользователь;\n",
    "- processed_dttm — дата расчёта витрины;\n",
    "- zone_id — идентификатор зоны (города);\n",
    "- local_time — локальное время."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/28 12:16:37 WARN CacheManager: Asked to cache already cached data.\n",
      "24/05/28 12:16:37 WARN CacheManager: Asked to cache already cached data.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|user_id|    subscription_set|\n",
      "+-------+--------------------+\n",
      "|      0|[247658, 658545, ...|\n",
      "|      6|[952414, 680730, ...|\n",
      "|      7|[647264, 594330, ...|\n",
      "|     19|[794489, 367857, ...|\n",
      "|     22|[300592, 410010, ...|\n",
      "|     25|[997444, 378549, ...|\n",
      "|     26|[832165, 978476, ...|\n",
      "|     29|[475118, 758368, ...|\n",
      "|     31|[980487, 978636, ...|\n",
      "|     32|[584995, 284651, ...|\n",
      "|     34|[498167, 648586, ...|\n",
      "|     39|[371530, 971965, ...|\n",
      "|     43|[590526, 592633, ...|\n",
      "|     50|[247040, 621916, ...|\n",
      "|     54|[78190, 200698, 6...|\n",
      "|     57|[877622, 311946, ...|\n",
      "|     58|[93479, 538602, 6...|\n",
      "|     65|[733803, 548496, ...|\n",
      "|     68|[568545, 770178, ...|\n",
      "|     71|[952414, 201612, ...|\n",
      "+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 164:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------------------+-----------+--------------------+\n",
      "|left_user|right_user|      processed_dttm|    zone_id|          local_time|\n",
      "+---------+----------+--------------------+-----------+--------------------+\n",
      "|     4360|      6664|2024-05-28 11:55:...|   Canberra|2021-04-29 03:12:...|\n",
      "|     8382|      9349|2024-05-28 11:55:...| Launceston|2021-05-24 01:19:...|\n",
      "|     6978|     11259|2024-05-28 11:55:...|   Maitland|2021-05-31 06:42:...|\n",
      "|    10205|     13101|2024-05-28 11:55:...|    Ipswich|2021-04-19 09:32:...|\n",
      "|     6317|     16521|2024-05-28 11:55:...| Cranbourne|2021-05-08 13:37:...|\n",
      "|     7137|     16834|2024-05-28 11:55:...|   Maitland|2021-05-10 12:11:...|\n",
      "|     2837|     18086|2024-05-28 11:55:...|   Maitland|2021-05-01 17:47:...|\n",
      "|     5950|     18203|2024-05-28 11:55:...| Launceston|2021-04-25 17:26:...|\n",
      "|    17371|     18358|2024-05-28 11:55:...| Cranbourne|2021-05-22 22:59:...|\n",
      "|     3610|     18700|2024-05-28 11:55:...|      Perth|2021-04-14 11:02:...|\n",
      "|    16371|     19099|2024-05-28 11:55:...|   Brisbane|2021-04-23 02:48:...|\n",
      "|     8543|     20061|2024-05-28 11:55:...|   Brisbane|2021-04-28 11:46:...|\n",
      "|     2698|     20785|2024-05-28 11:55:...|  Newcastle|2021-05-20 17:49:...|\n",
      "|    19635|     21265|2024-05-28 11:55:...|Rockhampton|2021-05-18 20:55:...|\n",
      "|     2418|     21770|2024-05-28 11:55:...|   Brisbane|2021-04-27 00:40:...|\n",
      "|     7051|     21799|2024-05-28 11:55:...| Launceston|2021-05-06 09:52:...|\n",
      "|    11874|     21926|2024-05-28 11:55:...| Launceston|2021-05-23 01:32:...|\n",
      "|    14570|     23510|2024-05-28 11:55:...|    Bendigo|2021-04-21 16:12:...|\n",
      "|    17717|     25487|2024-05-28 11:55:...|     Sydney|2021-04-14 20:22:...|\n",
      "|    15461|     26221|2024-05-28 11:55:...|      Perth|2021-04-27 00:38:...|\n",
      "+---------+----------+--------------------+-----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from typing  import List\n",
    "import pyspark\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.window import Window\n",
    "import pyspark.sql.functions as F\n",
    "import os \n",
    "import sys\n",
    "\n",
    "os.environ[\"HADOOP_CONF_DIR\"] = \"/etc/hadoop/conf\"\n",
    "os.environ[\"YARN_CONF_DIR\"] = \"/etc/hadoop/conf\"\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"/usr/bin/python3\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"/usr/bin/python3\"\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "                    .master(\"yarn\") \\\n",
    "                    .appName(\"datamartFriendsRecomendationJob\") \\\n",
    "                    .config(\"spark.executor.memory\", \"2g\") \\\n",
    "                    .config(\"spark.executor.cores\", \"2\") \\\n",
    "                    .getOrCreate()\n",
    "\n",
    "\n",
    "def input_paths(date: str, depth: int, base_path: str) -> List:\n",
    "    dt = datetime.strptime(date, '%Y-%m-%d').date()\n",
    "    path_list = [base_path + '/date=' + (dt - timedelta(days=i)).strftime('%Y-%m-%d')\n",
    "                 for i in range(depth)\n",
    "                ]\n",
    "    return path_list\n",
    "\n",
    "\n",
    "def datamart_friends_recomendation(base_path:str, date: str, depth: int, spark: SparkSession) -> DataFrame:\n",
    "\n",
    "    EARTH_RADIUS = 6371\n",
    "\n",
    "    events_path = input_paths(date, depth, base_path)\n",
    "#     print(events_path)\n",
    "    events = spark.read.option('basePath', base_path).parquet(*events_path)\n",
    "#     events.printSchema()\n",
    "\n",
    "    schema_geo_csv = StructType([ \n",
    "        StructField(\"id\",IntegerType(),True), \n",
    "        StructField(\"city\",StringType(),True), \n",
    "        StructField(\"lat\",StringType(),True), \n",
    "        StructField(\"lng\",StringType(),True)\n",
    "    ])    \n",
    "    \n",
    "    geo_city = spark.read.options(delimiter=\";\", header=True) \\\n",
    "                         .schema(schema_geo_csv) \\\n",
    "                         .csv(\"/user/yurgen001/data/snapshots/geo_city\") \\\n",
    "                         .withColumn(\"lat\", F.regexp_replace(\"lat\", \",\", \".\").cast(DoubleType())) \\\n",
    "                         .withColumn(\"lng\", F.regexp_replace(\"lng\", \",\", \".\").cast(DoubleType()))\n",
    "#     geo_city.printSchema()\n",
    "#     geo_city.show(10)\n",
    "\n",
    "       \n",
    "    \n",
    "    messages = events.where(\"event_type = 'message' AND event.message_ts IS NOT NULL\") \\\n",
    "                     .selectExpr(\"event.message_from AS user_id\",\n",
    "                                 \"event.message_ts AS message_dt\",\n",
    "                                 \"lat AS message_lat\",\n",
    "                                 \"lon AS message_lon\") \\\n",
    "                     .crossJoin(geo_city.withColumnRenamed(\"lat\", \"city_lat\") \\\n",
    "                                        .withColumnRenamed(\"lng\", \"city_lon\")) \n",
    "\n",
    "#     messages.show()\n",
    "  \n",
    "\n",
    "    \n",
    "    messages_with_distance = messages.withColumn(\"distance\", 2 * EARTH_RADIUS * F.asin(F.sqrt(F.pow(F.sin((F.radians('message_lat') - F.radians('city_lat')) / F.lit(2)), F.lit(2)) \\\n",
    "                    + F.cos(F.radians('message_lat')) * F.cos(F.radians('city_lat')) * F.pow(F.sin((F.radians('message_lon') - F.radians('city_lon')) / F.lit(2)), F.lit(2))))\n",
    "                                                )\n",
    "    \n",
    "#     messages_with_distance.show()\n",
    "    distance_rank_window = Window().partitionBy(\"user_id\", \"message_dt\").orderBy(\"distance\")\n",
    "    messages_with_city = messages_with_distance.select(\"user_id\",\n",
    "                                                       \"message_dt\",\n",
    "                                                       \"message_lat\",\n",
    "                                                       \"message_lon\",\n",
    "                                                       \"city\",\n",
    "                                                       \"distance\") \\\n",
    "                                               .withColumn(\"distance_rank\", F.row_number().over(distance_rank_window)) \\\n",
    "                                               .where(\"distance_rank = 1\") \\\n",
    "                                               .select(\"user_id\",\n",
    "                                                       \"message_dt\",\n",
    "                                                       \"message_lat\",\n",
    "                                                       \"message_lon\",\n",
    "                                                       \"city\")\n",
    "    \n",
    "    messages_with_city.cache()\n",
    "#     messages_with_city.show()\n",
    "\n",
    "    last_dt_window = Window().partitionBy(\"user_id\").orderBy(F.desc(\"message_dt\"))\n",
    "    user_act_location = messages_with_city.withColumn(\"dt_rank\", F.row_number().over(last_dt_window)) \\\n",
    "                                          .where(\"dt_rank = 1\") \\\n",
    "                                          .selectExpr(\"user_id\",\n",
    "                                                      \"message_lat AS act_lat\",\n",
    "                                                      \"message_lon AS act_lon\",\n",
    "                                                      \"city AS act_city\", \n",
    "                                                      \"CONCAT('Australia/', city) AS time_zone\",\n",
    "                                                      \"FROM_UTC_TIMESTAMP(message_dt, CONCAT('Australia/', 'Sydney')) AS local_time\"                            \n",
    "                                                      ) \n",
    "\n",
    "    # user_act_location.show(20, False)\n",
    "    \"\"\"\n",
    "        ___________________________________________________________________________________\n",
    "        до этого места вычисления те же, что и в первой витрине по пользователям\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "        Формируем таблицу соседей.\n",
    "        Джойним таблицу текущего местоположения пользоваетеля с самой собой по условию неравенства F.col(\"df_left.user_id\") < F.col(\"df_right.user_id\")\n",
    "        Получим недублированнеы пары пользователей, как надо по условию задачи\n",
    "        при этом id левого пользователя всегда меньше id правого\n",
    "        Далее сичтаем расстояние между ними в километрах и фильтруем тех, кто расположен ближе одного километра друг от друга\n",
    "    \"\"\"\n",
    "    neighbors = user_act_location.alias(\"df_left\").join(user_act_location.alias(\"df_right\"), F.col(\"df_left.user_id\") < F.col(\"df_right.user_id\"), 'inner') \\\n",
    "        .withColumn(\"distance\", 2 * EARTH_RADIUS * F.expr(\"asin(sqrt(pow(sin((radians(df_left.act_lat) - radians(df_right.act_lat)) / 2), 2)\"\n",
    "        \" + cos(radians(df_left.act_lat)) * cos(radians(df_right.act_lat)) * pow(sin((radians(df_left.act_lon) - radians(df_right.act_lon)) / 2), 2)))\")\n",
    "                   ) \\\n",
    "                                .where(\"distance < 1\") \\\n",
    "                                .selectExpr(\"df_left.user_id AS left_user\",\n",
    "                                            \"df_right.user_id AS right_user\",\n",
    "                                            \"CURRENT_TIMESTAMP() AS processed_dttm\",\n",
    "                                            \"df_left.act_city AS zone_id\",\n",
    "                                            \"GREATEST(df_left.local_time, df_right.local_time) AS local_time\"\n",
    "                                           )\n",
    "\n",
    "#     neighbors.show()\n",
    "\n",
    "#     messages_from_left_user = events.where(\"event_type = 'message'\") \\\n",
    "#                                     .selectExpr(\"event.message_from AS message_from\",\n",
    "#                                                 \"event.message_to AS message_to\") \\\n",
    "#                                     .join(neighbors.select(\"left_user\"), neighbors[\"left_user\"] == F.col(\"message_from\"), \"inner\") \\\n",
    "#                                     .selectExpr(\"left_user\",\n",
    "#                                                 \"message_to AS right_user\")\n",
    "\n",
    "# #     messages_from_left_user.show()\n",
    "\n",
    "#     messages_to_left_user = events.where(\"event_type = 'message'\") \\\n",
    "#                                   .selectExpr(\"event.message_from AS message_from\",\n",
    "#                                              \"event.message_to AS message_to\") \\\n",
    "#                                   .join(neighbors.select(\"left_user\"), neighbors[\"left_user\"] == F.col(\"message_to\"), \"inner\") \\\n",
    "#                                   .selectExpr(\"left_user\",\n",
    "#                                              \"message_from AS right_user\")\n",
    "# #     messages_to_left_user.show()\n",
    "\n",
    "#     left_user_correspondents = messages_from_left_user.unionByName(messages_to_left_user) \\\n",
    "#                                                       .na.drop()\n",
    "    \n",
    "#     left_user_correspondents.show()\n",
    "    \"\"\"\n",
    "        Формируем таблицу корреспондентов из общей таблицы событий таким образом,\n",
    "        что id левого пользователя всегда меньше id правого пользователя\n",
    "    \"\"\"\n",
    "\n",
    "    correspondents = events.where(\"event_type = 'message' AND event.message_from IS NOT NULL AND event.message_to IS NOT NULL\") \\\n",
    "                           .selectExpr(\"\"\"\n",
    "                                          CASE \n",
    "                                            WHEN event.message_from < event.message_to THEN event.message_from\n",
    "                                            ELSE event.message_to  \n",
    "                                          END AS left_user\n",
    "                                       \"\"\",\n",
    "                                       \"\"\"\n",
    "                                         CASE \n",
    "                                            WHEN event.message_from > event.message_to THEN event.message_from\n",
    "                                            ELSE event.message_to  \n",
    "                                          END AS right_user\n",
    "                                       \"\"\"\n",
    "                                     ) \n",
    "\n",
    "#     correspondents.show()\n",
    "    \"\"\"\n",
    "        Из таблицы соседей выбираем те пары, которые не обменивались сообщениями\n",
    "    \"\"\"\n",
    "    neighbors_without_messages = neighbors.join(correspondents, [\"left_user\", \"right_user\"], \"leftanti\") \n",
    "    \n",
    "    neighbors_without_messages.cache()\n",
    "#     neighbors_without_messages.show()\n",
    "    \n",
    "#     left_user_subscriptions = events.where(\"event_type = 'subscription'\") \\\n",
    "#                              .selectExpr(\"CAST(event.user AS LONG) AS left_user\",\n",
    "#                                          \"event.subscription_channel AS subscription_channel\") \\\n",
    "#                              .join(neighbors_without_messages.select(\"left_user\"), [\"left_user\"], \"inner\") \\\n",
    "#                              .selectExpr(\"left_user\",\n",
    "#                                          \"subscription_channel\")\n",
    "\n",
    "# #     left_user_subscriptions.show()\n",
    "    \n",
    "#     right_user_subscritions = events.where(\"event_type = 'subscription'\") \\\n",
    "#                               .selectExpr(\"CAST(event.user AS LONG) AS right_user\",\n",
    "#                                           \"event.subscription_channel AS subscription_channel\") \\\n",
    "#                               .join(neighbors_without_messages.select(\"right_user\"), [\"right_user\"], \"inner\") \\\n",
    "#                               .selectExpr(\"right_user\",\n",
    "#                                           \"subscription_channel\")\n",
    "    \n",
    "# #     right_user_subscritions.show()\n",
    "    \n",
    "#     common_subscribers = left_user_subscriptions.join(right_user_subscritions, [\"subscription_channel\"], \"inner\") \\\n",
    "#                                          .select(\"left_user\",\n",
    "#                                                  \"right_user\")\n",
    "    \n",
    "#     common_subscribers.show()\n",
    "\n",
    "    # friends_recomendation = neighbors_without_messages.join(common_subscribers, [\"left_user\", \"right_user\"], \"leftsemi\") \\\n",
    "    #                                                   .select(\"left_user\",\n",
    "    #                                                           \"right_user\",\n",
    "    #                                                           \"processed_dttm\",\n",
    "    #                                                           \"zone_id\",\n",
    "    #                                                           \"local_time\") \n",
    "\n",
    "    \"\"\"\n",
    "        из таблицы событий выбираем события подписки, группируем по пользователю и \n",
    "        формируем для каждого пользователя множество каналов, на которые он подписан\n",
    "    \"\"\"\n",
    "    user_subscriptions = events.where(\"event_type = 'subscription'\") \\\n",
    "                               .selectExpr(\"CAST(event.user AS LONG) AS user_id\",\n",
    "                                           \"event.subscription_channel AS subscription_channel\") \\\n",
    "                               .groupBy(\"user_id\") \\\n",
    "                               .agg(F.collect_set(\"subscription_channel\").alias(\"subscription_set\"))\n",
    "    user_subscriptions.show()\n",
    "\n",
    "    \"\"\"\n",
    "        формируем выходную витрину на основе таблицы соседей, не обменивавшихся сообщениями\n",
    "        джойним их списки каналов, получваем пересечение списков\n",
    "        и выбираем те пары корреспондентов, у которыъх пересечение не пустое (есть общие каналы в подписках)\n",
    "    \"\"\"\n",
    "\n",
    "    friends_recomendation = neighbors_without_messages.join(user_subscriptions.alias(\"l_sub\"), F.expr(\"left_user = l_sub.user_id\"), \"inner\") \\\n",
    "                                                      .join(user_subscriptions.alias(\"r_sub\"), F.expr(\"right_user = r_sub.user_id\"), \"inner\") \\\n",
    "                                                      .withColumn(\"common_subscriptions\", F.expr(\"ARRAY_INTERSECT(l_sub.subscription_set, r_sub.subscription_set)\")) \\\n",
    "                                                      .where(\"size(common_subscriptions) > 0\") \\\n",
    "                                                      .select(\"left_user\",\n",
    "                                                              \"right_user\",\n",
    "                                                              \"processed_dttm\",\n",
    "                                                              \"zone_id\",\n",
    "                                                              \"local_time\") \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    friends_recomendation.show()\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    datamart_friends_recomendation(\"/user/yurgen001/data/geo/events\", '2022-05-31', 60, spark)#.repartition(1) \\\n",
    "        #.write.mode('overwrite').parquet('/user/yurgen001/data/analytics/dm_friends_recomendation_d60')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/26 16:28:16 WARN CacheManager: Asked to cache already cached data.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----------+-----+----+\n",
      "|event_date|event_type|    zone_id|month|week|\n",
      "+----------+----------+-----------+-----+----+\n",
      "|2021-04-25|   message|      Perth|    4|   4|\n",
      "|2021-04-29|   message|     Sydney|    4|   5|\n",
      "|2021-04-25|   message|  Melbourne|    4|   4|\n",
      "|2021-05-07|   message|     Darwin|    5|   2|\n",
      "|2021-05-20|   message|    Bendigo|    5|   3|\n",
      "|2021-04-27|   message|      Perth|    4|   4|\n",
      "|2021-05-04|   message|   Brisbane|    5|   1|\n",
      "|2021-04-28|   message|   Brisbane|    4|   5|\n",
      "|2021-05-10|   message|   Brisbane|    5|   2|\n",
      "|2021-05-04|   message|    Geelong|    5|   1|\n",
      "|2021-04-25|   message|    Geelong|    4|   4|\n",
      "|2021-04-24|   message|     Sydney|    4|   4|\n",
      "|2021-05-03|   message|   Canberra|    5|   1|\n",
      "|2021-06-05|   message|Rockhampton|    6|   1|\n",
      "|2021-05-07|   message|  Newcastle|    5|   2|\n",
      "|2021-05-20|   message|    Bendigo|    5|   3|\n",
      "|2021-05-08|   message|      Perth|    5|   2|\n",
      "|2021-04-23|   message|     Cairns|    4|   4|\n",
      "|2021-04-23|   message|     Cairns|    4|   4|\n",
      "|2021-04-26|   message|     Cairns|    4|   4|\n",
      "+----------+----------+-----------+-----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 421:============>(357 + 2) / 359][Stage 423:>                (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+----------+------------+-------------+-----------------+---------+-------------+--------------+------------------+----------+\n",
      "|month|week|   zone_id|week_message|week_reaction|week_subscription|week_user|month_message|month_reaction|month_subscription|month_user|\n",
      "+-----+----+----------+------------+-------------+-----------------+---------+-------------+--------------+------------------+----------+\n",
      "|    5|   1|  Canberra|         432|         2950|             5797|        0|         1101|         22655|             45704|         0|\n",
      "|    5|   2|  Canberra|         285|         4002|             8019|        0|         1101|         22655|             45704|         0|\n",
      "|    5|   3|  Canberra|         236|         4938|             9691|        0|         1101|         22655|             45704|         0|\n",
      "|    5|   4|  Canberra|         119|         6564|            12936|        0|         1101|         22655|             45704|         0|\n",
      "|    5|   5|  Canberra|          29|         4201|             9261|        0|         1101|         22655|             45704|         0|\n",
      "|    6|   3|  Brisbane|           5|            0|                0|        0|          124|             0|                 0|         0|\n",
      "|    6|   2|  Brisbane|          33|            0|                0|        0|          124|             0|                 0|         0|\n",
      "|    6|   1|  Brisbane|          86|            0|                0|        0|          124|             0|                 0|         0|\n",
      "|    4|   5|Gold Coast|         158|         1173|             2206|        0|          537|          3019|              5597|         0|\n",
      "|    4|   4|Gold Coast|         379|         1846|             3391|        0|          537|          3019|              5597|         0|\n",
      "|    4|   5|   Bendigo|         989|         3131|             5950|        0|         2789|          7929|             14800|         0|\n",
      "|    4|   4|   Bendigo|        1800|         4798|             8850|        0|         2789|          7929|             14800|         0|\n",
      "|    6|   2| Toowoomba|           1|            0|                0|        0|            7|             0|                 0|         0|\n",
      "|    6|   1| Toowoomba|           6|            0|                0|        0|            7|             0|                 0|         0|\n",
      "|    6|   3|    Cairns|           2|            0|                0|        0|           30|             0|                 0|         0|\n",
      "|    6|   1|    Cairns|          21|            0|                0|        0|           30|             0|                 0|         0|\n",
      "|    6|   4|    Cairns|           1|            0|                0|        0|           30|             0|                 0|         0|\n",
      "|    6|   2|    Cairns|           6|            0|                0|        0|           30|             0|                 0|         0|\n",
      "|    6|   2|  Ballarat|           5|            0|                0|        0|           12|             0|                 0|         0|\n",
      "|    6|   1|  Ballarat|           7|            0|                0|        0|           12|             0|                 0|         0|\n",
      "+-----+----+----------+------------+-------------+-----------------+---------+-------------+--------------+------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from typing  import List, Tuple\n",
    "import pyspark\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.window import Window\n",
    "import pyspark.sql.functions as F\n",
    "import os \n",
    "import sys\n",
    "\n",
    "os.environ[\"HADOOP_CONF_DIR\"] = \"/etc/hadoop/conf\"\n",
    "os.environ[\"YARN_CONF_DIR\"] = \"/etc/hadoop/conf\"\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"/usr/bin/python3\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"/usr/bin/python3\"\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "                    .master(\"yarn\") \\\n",
    "                    .appName(\"datamartFriendsRecomendationJob\") \\\n",
    "                    .config(\"spark.executor.memory\", \"2g\") \\\n",
    "                    .config(\"spark.executor.cores\", \"2\") \\\n",
    "                    .getOrCreate()\n",
    "\n",
    "\n",
    "def input_paths(date: str, depth: int, base_path: str) -> List:\n",
    "    dt = datetime.strptime(date, '%Y-%m-%d').date()\n",
    "    path_list = [base_path + '/date=' + (dt - timedelta(days=i)).strftime('%Y-%m-%d')\n",
    "                 for i in range(depth)\n",
    "                ]\n",
    "    return path_list\n",
    "\n",
    "\n",
    "def common_load_and_calculation(base_path:str, date: str, depth: int, spark: SparkSession) -> Tuple[DataFrame]:\n",
    "\n",
    "    EARTH_RADIUS = 6371\n",
    "\n",
    "    events_path = input_paths(date, depth, base_path)\n",
    "#     print(events_path)\n",
    "    events = spark.read.option('basePath', base_path).parquet(*events_path)\n",
    "#     events.printSchema()\n",
    "\n",
    "    schema_geo_csv = StructType([ \n",
    "        StructField(\"id\",IntegerType(),True), \n",
    "        StructField(\"city\",StringType(),True), \n",
    "        StructField(\"lat\",StringType(),True), \n",
    "        StructField(\"lng\",StringType(),True)\n",
    "    ])    \n",
    "    \n",
    "    geo_city = spark.read.options(delimiter=\";\", header=True) \\\n",
    "                         .schema(schema_geo_csv) \\\n",
    "                         .csv(\"/user/yurgen001/data/snapshots/geo_city\") \\\n",
    "                         .withColumn(\"lat\", F.regexp_replace(\"lat\", \",\", \".\").cast(DoubleType())) \\\n",
    "                         .withColumn(\"lng\", F.regexp_replace(\"lng\", \",\", \".\").cast(DoubleType()))\n",
    "#     geo_city.printSchema()\n",
    "#     geo_city.show(10)\n",
    "\n",
    "       \n",
    "    \n",
    "    messages = events.where(\"event_type = 'message' AND event.message_ts IS NOT NULL\") \\\n",
    "                     .selectExpr(\"event.message_from AS user_id\",\n",
    "                                 \"event.message_ts AS message_dt\",\n",
    "                                 \"lat AS message_lat\",\n",
    "                                 \"lon AS message_lon\") \\\n",
    "                     .crossJoin(geo_city.withColumnRenamed(\"lat\", \"city_lat\") \\\n",
    "                                        .withColumnRenamed(\"lng\", \"city_lon\")) \n",
    "\n",
    "#     messages.show()\n",
    "  \n",
    "\n",
    "    \n",
    "    messages_with_distance = messages.withColumn(\"distance\", 2 * EARTH_RADIUS * F.asin(F.sqrt(F.pow(F.sin((F.radians('message_lat') - F.radians('city_lat')) / F.lit(2)), F.lit(2)) \\\n",
    "                    + F.cos(F.radians('message_lat')) * F.cos(F.radians('city_lat')) * F.pow(F.sin((F.radians('message_lon') - F.radians('city_lon')) / F.lit(2)), F.lit(2))))\n",
    "                                                )\n",
    "    \n",
    "#     messages_with_distance.show()\n",
    "    distance_rank_window = Window().partitionBy(\"user_id\", \"message_dt\").orderBy(\"distance\")\n",
    "    messages_with_city = messages_with_distance.select(\"user_id\",\n",
    "                                                       \"message_dt\",\n",
    "                                                       \"message_lat\",\n",
    "                                                       \"message_lon\",\n",
    "                                                       \"city\",\n",
    "                                                       \"distance\") \\\n",
    "                                               .withColumn(\"distance_rank\", F.row_number().over(distance_rank_window)) \\\n",
    "                                               .where(\"distance_rank = 1\") \\\n",
    "                                               .select(\"user_id\",\n",
    "                                                       \"message_dt\",\n",
    "                                                       \"message_lat\",\n",
    "                                                       \"message_lon\",\n",
    "                                                       \"city\")\n",
    "    \n",
    "    messages_with_city.cache()\n",
    "#     messages_with_city.show()\n",
    "\n",
    "    last_dt_window = Window().partitionBy(\"user_id\").orderBy(F.desc(\"message_dt\"))\n",
    "    user_act_location = messages_with_city.withColumn(\"dt_rank\", F.row_number().over(last_dt_window)) \\\n",
    "                                          .where(\"dt_rank = 1\") \\\n",
    "                                          .selectExpr(\"user_id\",\n",
    "                                                      \"message_lat AS act_lat\",\n",
    "                                                      \"message_lon AS act_lon\",\n",
    "                                                      \"city AS act_city\", \n",
    "                                                      \"CONCAT('Australia/', city) AS time_zone\",\n",
    "                                                      \"FROM_UTC_TIMESTAMP(message_dt, CONCAT('Australia/', 'Sydney')) AS local_time\"                            \n",
    "                                                      ) \n",
    "\n",
    "    # user_act_location.show(20, False)\n",
    "    return (events,\n",
    "            messages_with_city,\n",
    "            user_act_location)\n",
    "\n",
    "\n",
    "\n",
    "def datamart_by_users(messages_with_city: DataFrame,\n",
    "                      user_act_location: DataFrame) -> DataFrame:\n",
    "\n",
    "    DAYS_COUNT = 27 # время непрерывного нахождения для определения домашнего города\n",
    "     \n",
    "    seq_num_window = Window().partitionBy(\"user_id\").orderBy(\"message_dt\")\n",
    "    seq_num_city_window = Window().partitionBy(\"user_id\", \"city\").orderBy(\"message_dt\")\n",
    "    user_city_visits = messages_with_city.withColumn(\"seq_num\", F.row_number().over(seq_num_window)) \\\n",
    "                                         .withColumn(\"seq_num_city\", F.row_number().over(seq_num_city_window)) \\\n",
    "                                         .withColumn(\"visit_num\", F.col(\"seq_num\") - F.col(\"seq_num_city\"))\n",
    "\n",
    "#     user_city_visits.show(40, False)\n",
    "    user_city_visits = user_city_visits.groupBy(\"user_id\", \"city\", \"visit_num\") \\\n",
    "                                       .agg(F.min(\"message_dt\").alias(\"start_visit_dt\"), \\\n",
    "                                            F.max(\"message_dt\").alias(\"end_visit_dt\"), \\\n",
    "                                           ) \\\n",
    "                                       .withColumn(\"visit_day_count\", F.datediff(F.to_date(\"end_visit_dt\"), F.to_date(\"start_visit_dt\")))\n",
    "#     user_city_visits.show(40, False)\n",
    "\n",
    "    home_city_window = Window().partitionBy(\"user_id\").orderBy(F.desc(\"start_visit_dt\"))\n",
    "    user_home_city = user_city_visits.where(f\"visit_day_count >= {DAYS_COUNT}\") \\\n",
    "                                     .withColumn(\"home_city_rank\", F.row_number().over(home_city_window)) \\\n",
    "                                     .where(\"home_city_rank = 1\") \\\n",
    "                                     .selectExpr(\"user_id\",\n",
    "                                                 \"city AS home_city\")             \n",
    "#     user_home_city.show()\n",
    "    \n",
    "    user_travel = user_city_visits.orderBy(\"start_visit_dt\") \\\n",
    "                                  .groupBy(\"user_id\") \\\n",
    "                                  .agg(F.count(\"city\").alias(\"travel_count\"), \\\n",
    "                                       F.collect_list(\"city\").alias(\"travel_array\")\n",
    "                                      )                     \n",
    "#     user_travel.show(40, False)\n",
    "    \n",
    "    user_datamart = user_act_location.join(user_travel, \"user_id\", \"left\") \\\n",
    "                                 .join(user_home_city, \"user_id\", \"left\") \\\n",
    "                                 .select(\"user_id\",\n",
    "                                         \"act_city\",\n",
    "                                         \"home_city\",\n",
    "                                         \"travel_count\",\n",
    "                                         \"travel_array\",\n",
    "                                         \"local_time\")\n",
    "    user_datamart.show()\n",
    "\n",
    "    return user_datamart\n",
    "\n",
    "\n",
    "\n",
    "def datamart_by_zone(events: DataFrame,\n",
    "                     messages_with_city: DataFrame,\n",
    "                     user_act_location: DataFrame) -> DataFrame:\n",
    "\n",
    "\n",
    "    out_messages = messages_with_city.selectExpr(\"TO_DATE(message_dt) AS event_date\",\n",
    "                                                 \"'message' AS event_type\",\n",
    "                                                 \"city AS zone_id\")\n",
    "    \n",
    "#     out_messages.show()\n",
    "\n",
    "\n",
    "    out_reactions = events.where(\"event_type = 'reaction'\") \\\n",
    "                      .selectExpr(\"CAST(event.reaction_from AS LONG) AS user_id\",\n",
    "                                  \"TO_DATE(event.datetime) AS event_date\") \\\n",
    "                      .join(user_act_location, \"user_id\", \"inner\") \\\n",
    "                      .selectExpr(\"event_date\",\n",
    "                                  \"'reaction' AS event_type\",\n",
    "                                  \"act_city AS zone_id\")\n",
    "    \n",
    "#     out_reactions.printSchema()\n",
    "#     out_reactions.show()\n",
    "    \n",
    "\n",
    "    out_subscriptions = events.where(\"event_type = 'subscription'\") \\\n",
    "                              .selectExpr(\"CAST(event.user AS LONG) AS user_id\",\n",
    "                                          \"TO_DATE(event.datetime) AS event_date\") \\\n",
    "                              .join(user_act_location, \"user_id\", \"inner\") \\\n",
    "                              .selectExpr(\"event_date\",\n",
    "                                          \"'subscription' AS event_type\",\n",
    "                                          \"act_city AS zone_id\")\n",
    "    \n",
    "#     out_subscriptions.printSchema()\n",
    "#     out_subscriptions.show()\n",
    "    \n",
    "    out_registrations = events.where(\"event_type = 'registration'\") \\\n",
    "                              .selectExpr(\"CAST(event.user AS LONG) AS user_id\",\n",
    "                                          \"TO_DATE(event.datetime) AS event_date\") \\\n",
    "                              .join(user_act_location, \"user_id\", \"inner\") \\\n",
    "                              .selectExpr(\"event_date\",\n",
    "                                          \"'registration' AS event_type\",\n",
    "                                          \"act_city AS zone_id\")\n",
    "\n",
    "#     out_registrations.printSchema()\n",
    "#     out_registrations.show()\n",
    "\n",
    "    all_events =  out_messages.unionByName(out_reactions) \\\n",
    "                              .unionByName(out_subscriptions) \\\n",
    "                              .unionByName(out_registrations) \\\n",
    "                              .withColumn(\"month\", F.month(\"event_date\")) \\\n",
    "                              .withColumn(\"week\", F.expr(\"FLOOR(DAYOFMONTH(event_date) / 7) + 1\"))\n",
    "    \n",
    "#     all_events.show()\n",
    "\n",
    "    zone_datamart_by_week = all_events.groupBy(\"zone_id\", \"month\", \"week\") \\\n",
    "                                      .pivot(\"event_type\", [\"message\", \"reaction\", \"subscription\", \"registration\"]) \\\n",
    "                                      .agg(F.count(\"event_date\")) \\\n",
    "                                      .withColumnRenamed(\"message\", \"week_message\") \\\n",
    "                                      .withColumnRenamed(\"reaction\", \"week_reaction\") \\\n",
    "                                      .withColumnRenamed(\"subscription\", \"week_subscription\") \\\n",
    "                                      .withColumnRenamed(\"registration\", \"week_user\")\n",
    "                                      \n",
    "    \n",
    "#     zone_datamart_by_week.show(100)\n",
    "    \n",
    "    zone_datamart_by_month = all_events.groupBy(\"zone_id\", \"month\") \\\n",
    "                                       .pivot(\"event_type\", [\"message\", \"reaction\", \"subscription\", \"registration\"]) \\\n",
    "                                       .agg(F.count(\"event_date\")) \\\n",
    "                                       .withColumnRenamed(\"message\", \"month_message\") \\\n",
    "                                       .withColumnRenamed(\"reaction\", \"month_reaction\") \\\n",
    "                                       .withColumnRenamed(\"subscription\", \"month_subscription\") \\\n",
    "                                       .withColumnRenamed(\"registration\", \"month_user\")\n",
    "                                      \n",
    "    \n",
    "#     zone_datamart_by_month.show(100)\n",
    "    \n",
    "    zone_datamart = zone_datamart_by_week.join(zone_datamart_by_month, [\"zone_id\", \"month\"], \"inner\") \\\n",
    "                                         .select(\"month\",\n",
    "                                                 \"week\",\n",
    "                                                 \"zone_id\",\n",
    "                                                 \"week_message\",\n",
    "                                                 \"week_reaction\",\n",
    "                                                 \"week_subscription\",\n",
    "                                                 \"week_user\",\n",
    "                                                 \"month_message\",\n",
    "                                                 \"month_reaction\",\n",
    "                                                 \"month_subscription\",\n",
    "                                                 \"month_user\",\n",
    "                                                ) \\\n",
    "                                         .na.fill(value=0)\n",
    "    zone_datamart.show()\n",
    "    return zone_datamart\n",
    "\n",
    "\n",
    "def datamart_friends_recomendation(events:DataFrame,\n",
    "                                   user_act_location: DataFrame) -> DataFrame:\n",
    "\n",
    "    EARTH_RADIUS = 6371\n",
    "\n",
    "    neighbors = user_act_location.alias(\"df_left\").join(user_act_location.alias(\"df_right\"), F.col(\"df_left.user_id\") < F.col(\"df_right.user_id\"), 'inner') \\\n",
    "        .withColumn(\"distance\", 2 * EARTH_RADIUS * F.expr(\"asin(sqrt(pow(sin((radians(df_left.act_lat) - radians(df_right.act_lat)) / 2), 2)\"\n",
    "        \" + cos(radians(df_left.act_lat)) * cos(radians(df_right.act_lat)) * pow(sin((radians(df_left.act_lon) - radians(df_right.act_lon)) / 2), 2)))\")\n",
    "                   ) \\\n",
    "                                .where(\"distance < 1\") \\\n",
    "                                .selectExpr(\"df_left.user_id AS left_user\",\n",
    "                                            \"df_right.user_id AS right_user\",\n",
    "                                            \"CURRENT_TIMESTAMP() AS processed_dttm\",\n",
    "                                            \"df_left.act_city AS zone_id\",\n",
    "                                            \"GREATEST(df_left.local_time, df_right.local_time) AS local_time\"\n",
    "                                           )\n",
    "\n",
    "#     neighbors.show()\n",
    "\n",
    "    messages_from_left_user = events.where(\"event_type = 'message'\") \\\n",
    "                                    .selectExpr(\"event.message_from AS message_from\",\n",
    "                                                \"event.message_to AS message_to\") \\\n",
    "                                    .join(neighbors.select(\"left_user\"), neighbors[\"left_user\"] == F.col(\"message_from\"), \"inner\") \\\n",
    "                                    .selectExpr(\"left_user\",\n",
    "                                                \"message_to AS right_user\")\n",
    "\n",
    "#     messages_from_left_user.show()\n",
    "\n",
    "    messages_to_left_user = events.where(\"event_type = 'message'\") \\\n",
    "                                 .selectExpr(\"event.message_from AS message_from\",\n",
    "                                             \"event.message_to AS message_to\") \\\n",
    "                                 .join(neighbors.select(\"left_user\"), neighbors[\"left_user\"] == F.col(\"message_to\"), \"inner\") \\\n",
    "                                 .selectExpr(\"left_user\",\n",
    "                                             \"message_from AS right_user\")\n",
    "#     messages_to_left_user.show()\n",
    "\n",
    "    left_user_correspondents = messages_from_left_user.unionByName(messages_to_left_user) \\\n",
    "                                                      .na.drop()\n",
    "    \n",
    "#     left_user_correspondents.show()\n",
    "\n",
    "    neighbors_without_messages = neighbors.join(left_user_correspondents, [\"left_user\", \"right_user\"], \"leftanti\") \n",
    "    \n",
    "    neighbors_without_messages.cache()\n",
    "#     neighbors_without_messages.show()\n",
    "    \n",
    "    left_user_subscriptions = events.where(\"event_type = 'subscription'\") \\\n",
    "                             .selectExpr(\"CAST(event.user AS LONG) AS left_user\",\n",
    "                                         \"event.subscription_channel AS subscription_channel\") \\\n",
    "                             .join(neighbors_without_messages.select(\"left_user\"), [\"left_user\"], \"inner\") \\\n",
    "                             .selectExpr(\"left_user\",\n",
    "                                         \"subscription_channel\")\n",
    "\n",
    "#     left_user_subscriptions.show()\n",
    "    \n",
    "    right_user_subscritions = events.where(\"event_type = 'subscription'\") \\\n",
    "                              .selectExpr(\"CAST(event.user AS LONG) AS right_user\",\n",
    "                                          \"event.subscription_channel AS subscription_channel\") \\\n",
    "                              .join(neighbors_without_messages.select(\"right_user\"), [\"right_user\"], \"inner\") \\\n",
    "                              .selectExpr(\"right_user\",\n",
    "                                          \"subscription_channel\")\n",
    "    \n",
    "#     right_user_subscritions.show()\n",
    "    \n",
    "    common_subscribers = left_user_subscriptions.join(right_user_subscritions, [\"subscription_channel\"], \"inner\") \\\n",
    "                                         .select(\"left_user\",\n",
    "                                                 \"right_user\")\n",
    "    \n",
    "#     common_subscribers.show()\n",
    "\n",
    "    friends_recomendation = neighbors_without_messages.join(common_subscribers, [\"left_user\", \"right_user\"], \"leftsemi\")\n",
    "\n",
    "    friends_recomendation.show()\n",
    "    return friends_recomendation\n",
    "    \n",
    "\n",
    "def datamarts_calculation(base_path:str, date: str, depth: int, spark: SparkSession) -> None:\n",
    "    \n",
    "    events, messages_with_city, user_act_location = common_load_and_calculation(base_path, date, depth, spark)\n",
    "\n",
    "    datamart_by_users(messages_with_city, user_act_location).write \\\n",
    "                                                            .mode('overwrite') \\\n",
    "                                                            .parquet(f'/user/yurgen001/data/analytics/dm_by_user_d{depth}/date={date}')\n",
    "\n",
    "    datamart_by_zone(events, messages_with_city, user_act_location).write \\\n",
    "                                                                   .mode('overwrite') \\\n",
    "                                                                   .parquet(f'/user/yurgen001/data/analytics/dm_by_zone_d{depth}/date={date}')\n",
    "\n",
    "    datamart_friends_recomendation(events, user_act_location).write \\\n",
    "                                                             .mode('overwrite') \\\n",
    "                                                             .parquet(f'/user/yurgen001/data/analytics/dm_friends_recomendation_d{depth}/date={date}')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    datamarts_calculation(\"/user/yurgen001/data/geo/events\", '2022-05-31', 60, spark)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
